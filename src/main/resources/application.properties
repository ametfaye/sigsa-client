app.version = 1.0.0
app.name = SIGSA
server.port = 8001
# ===============================
# = DATASOURCE POSTGRES SQL
# ===============================

#OVH
#spring.datasource.url=jdbc:postgresql://141.95.173.56:5432/sigam_dev
#spring.datasource.username =sigam
#spring.datasource.password =sigam**

#LOCAL
spring.datasource.url=jdbc:postgresql://localhost:5433/sigsa-ca
spring.datasource.username =postgres
spring.datasource.password =postgres

spring.datasource.testWhileIdle = true
spring.datasource.validationQuery = SELECT 1
# ===============================
# = JSF SERVLET CONFIG
# ===============================
primefaces.CLIENT_SIDE_VALIDATION=true
javax.faces.STATE_SAVING_METHOD=client
primefaces.THEME=bootstrap

# ===============================
# = UPGRADE THE SIZE OF MAX FILE UPLOAD SPRING BOOT (DEFAULT WAS 2MO)
# ===============================
spring.http.multipart.max-file-size=100MB
spring.http.multipart.max-request-size=100MB

# ===============================
# = JPA / HIBERNATE
# ===============================
spring.jpa.show-sql = true
spring.jpa.hibernate.ddl-auto = update
spring.jpa.hibernate.naming-strategy = org.hibernate.cfg.ImprovedNamingStrategy
spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.PostgreSQLDialect

# ===============================
# = Thymeleaf configurations
# ===============================
spring.thymeleaf.mode=LEGACYHTML5
spring.thymeleaf.cache=false


# Required connection configs for Kafka producer, consumer, and admin
#spring.kafka.properties.sasl.mechanism=PLAIN
#spring.kafka.properties.bootstrap.servers=pkc-p11xm.us-east-1.aws.confluent.cloud:9092
#spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='REVP7H6E5574B5ZL' password='4SPucNl9o6VsVC9PPwHRZzOMhuWYvpBYUcq91NxkCRX+4jjAUdc4h6SZXr7Mo10J';
#spring.kafka.properties.security.protocol=SASL_SSL

# Best practice for higher availability in Apache Kafka clients prior to 3.0
#spring.kafka.properties.session.timeout.ms=45000

# Required connection configs for Confluent Cloud Schema Registry
#spring.kafka.properties.basic.auth.credentials.source=USER_INFO
#spring.kafka.properties.basic.auth.user.info=REVP7H6E5574B5ZL:4SPucNl9o6VsVC9PPwHRZzOMhuWYvpBYUcq91NxkCRX+4jjAUdc4h6SZXr7Mo10J
#spring.kafka.properties.schema.registry.url=https://psrc-vrpp5.us-east-2.aws.confluent.cloud

spring.kafka.bootstrap-servers=http://141.95.173.56:9092
# consumer config

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer

# producer config

spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer




# ==============================================================
# = Spring Security / Queries for AuthenticationManagerBuilder  
# ==============================================================
spring.queries.users-query=select identifiant, password, active from user_infos where identifiant=? and active = 1 and deleted = 0
spring.queries.roles-query=select u.identifiant, r.role from user_infos u inner join user_role ur on(u.user_id=ur.user_id) inner join role r on(ur.role_id=r.role_id) where u.identifiant=? and active = 1 and deleted = 0

odm.app.url = http://localhost:8500


server.tomcat.additional-tld-skip-patterns=*.jar

#org.cages.files.path = /documents_sigma
org.cages.files.path = /home/sigam/documents/